{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we scrape data from Wikipedia. We want to access the tables that register the terror attacks that happened at some point in the past. There are some Wikipedia articles (such as https://en.wikipedia.org/wiki/List_of_terrorist_incidents_in_January-June_2011) that do exactly that. The data is presented as tables, and all the articles that we need present data in this form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple map of month name to its number\n",
    "month_to_int = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "\n",
    "# Reversed map\n",
    "int_to_month = {i: m for m, i in month_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The wikipedia URL that every article has in common\n",
    "base_url = 'https://en.wikipedia.org/wiki/List_of_terrorist_incidents_in_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show all the articles that we are going to use to find the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['January-June_2011',\n",
       " 'July-December_2011',\n",
       " 'January-June_2012',\n",
       " 'July-December_2012',\n",
       " 'January-June_2013',\n",
       " 'July-December_2013',\n",
       " 'January-June_2014',\n",
       " 'July-December_2014',\n",
       " 'January_2015',\n",
       " 'February_2015',\n",
       " 'March_2015',\n",
       " 'April_2015',\n",
       " 'May_2015',\n",
       " 'June_2015',\n",
       " 'July_2015',\n",
       " 'August_2015',\n",
       " 'September_2015',\n",
       " 'October_2015',\n",
       " 'November_2015',\n",
       " 'December_2015',\n",
       " 'January_2016',\n",
       " 'February_2016',\n",
       " 'March_2016',\n",
       " 'April_2016',\n",
       " 'May_2016',\n",
       " 'June_2016',\n",
       " 'July_2016',\n",
       " 'August_2016',\n",
       " 'September_2016',\n",
       " 'October_2016',\n",
       " 'November_2016',\n",
       " 'December_2016',\n",
       " 'January_2017',\n",
       " 'February_2017',\n",
       " 'March_2017',\n",
       " 'April_2017',\n",
       " 'May_2017',\n",
       " 'June_2017',\n",
       " 'July_2017',\n",
       " 'August_2017',\n",
       " 'September_2017',\n",
       " 'October_2017',\n",
       " 'November_2017',\n",
       " 'December_2017']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All specific end of the wikipedia URL, along with the corresponding month numbers of the article\n",
    "times = {}\n",
    "\n",
    "for year in range(2011, 2015):\n",
    "    # For years 2011 to 2014, the articles appear biyearly\n",
    "    times.update({'January-June_' + str(year): list(range(1, 7))})\n",
    "    times.update({'July-December_' + str(year): list(range(7, 13))})\n",
    "    \n",
    "for year in range(2015, 2018):\n",
    "    # For years 2015 to 2017, the articles appear monthly\n",
    "    for month, int_ in month_to_int.items():\n",
    "        times.update({month + '_' + str(year): [int_]})\n",
    "        \n",
    "list(times.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_int(s):\n",
    "    '''Returns the first integer found in s'''\n",
    "    i = re.findall('\\d+', s)\n",
    "    return int(i[0]) if len(i) > 0 else float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_date(s, year):\n",
    "    '''Returns a date from the datetime library from a string like \\'January 1\\''''\n",
    "    l = s.split(' ')\n",
    "    return date(to_int(year), month_to_int[l[0]], to_int(l[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiki_table_to_df(end_url, month_range, base_url=base_url):\n",
    "    '''Creates a dataframe from the tables available in the wikipedia page'''\n",
    "    print('Scraping for', end_url)\n",
    "    r = requests.get(base_url + end_url) # Get request\n",
    "    soup = BeautifulSoup(r.text, 'lxml') # Parse HTML\n",
    "    wiki_tables = soup.findAll('table', {'class': 'wikitable sortable'}) # Get tables from the wikipedia page\n",
    "\n",
    "    table = []\n",
    "\n",
    "    for month_int, wiki_table in zip(month_range, wiki_tables):\n",
    "        for row in wiki_table.findAll('tr'):\n",
    "            elems = row.findAll('td') \n",
    "            if len(elems) != 0:\n",
    "                interesting = [elem.text for elem in elems[:5]]\n",
    "                 # First element is the day of the month, but we add the name of the month as well in front of it\n",
    "                interesting[0] = int_to_month[month_int] + ' ' + interesting[0]\n",
    "                table.append(interesting)\n",
    "                \n",
    "    df = pd.DataFrame(table, columns=['date', 'type', 'deaths', 'injuries', 'location'])\n",
    "    df.date = df.date.apply(lambda s: to_date(s, end_url[-4:])) # Translate the date with the year defined by the end_url arg\n",
    "    df.deaths = df.deaths.apply(to_int) # Map death number to int\n",
    "    df.injuries = df.injuries.apply(to_int) # Map injuries number to int\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for January-June_2011\n",
      "Scraping for July-December_2011\n",
      "Scraping for January-June_2012\n",
      "Scraping for July-December_2012\n",
      "Scraping for January-June_2013\n",
      "Scraping for July-December_2013\n",
      "Scraping for January-June_2014\n",
      "Scraping for July-December_2014\n",
      "Scraping for January_2015\n",
      "Scraping for February_2015\n",
      "Scraping for March_2015\n",
      "Scraping for April_2015\n",
      "Scraping for May_2015\n",
      "Scraping for June_2015\n",
      "Scraping for July_2015\n",
      "Scraping for August_2015\n",
      "Scraping for September_2015\n",
      "Scraping for October_2015\n",
      "Scraping for November_2015\n",
      "Scraping for December_2015\n",
      "Scraping for January_2016\n",
      "Scraping for February_2016\n",
      "Scraping for March_2016\n",
      "Scraping for April_2016\n",
      "Scraping for May_2016\n",
      "Scraping for June_2016\n",
      "Scraping for July_2016\n",
      "Scraping for August_2016\n",
      "Scraping for September_2016\n",
      "Scraping for October_2016\n",
      "Scraping for November_2016\n",
      "Scraping for December_2016\n",
      "Scraping for January_2017\n",
      "Scraping for February_2017\n",
      "Scraping for March_2017\n",
      "Scraping for April_2017\n",
      "Scraping for May_2017\n",
      "Scraping for June_2017\n",
      "Scraping for July_2017\n",
      "Scraping for August_2017\n",
      "Scraping for September_2017\n",
      "Scraping for October_2017\n",
      "Scraping for November_2017\n",
      "Scraping for December_2017\n",
      "We have 4664 registered attacks from January 1st, 2011 up to today (November 28th, 2017)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Get a DataFrame for every article from 2011 to 2017\n",
    "for time, month_range in times.items():\n",
    "    dfs.append(wiki_table_to_df(time, month_range))\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "print('We have {} registered attacks from January 1st, 2011 up to today (November 28th, 2017)'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what some of the entries of the final result look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>deaths</th>\n",
       "      <th>injuries</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Suicide bombing</td>\n",
       "      <td>21.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Alexandria, Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>Raid</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Zamboanga, Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>37</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>Shooting, Melee attack</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Jerusalem, Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>41</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>Bombing</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kandahar province, Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        date                    type  deaths  injuries  \\\n",
       "0         0  2011-01-01         Suicide bombing    21.0      97.0   \n",
       "56       56  2011-02-13                    Raid     7.0       5.0   \n",
       "1033     37  2014-11-18  Shooting, Melee attack     5.0       7.0   \n",
       "4663     41  2017-11-28                 Bombing     8.0       NaN   \n",
       "\n",
       "                            location  \n",
       "0                  Alexandria, Egypt  \n",
       "56            Zamboanga, Philippines  \n",
       "1033               Jerusalem, Israel  \n",
       "4663  Kandahar province, Afghanistan  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0, 56, 1033, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reindex and save\n",
    "df.to_csv('attacks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
