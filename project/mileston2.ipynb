{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Project : Milestone 2 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will introduce you to the dataset that we chose by locally importing a part of in, and store it in a dataframe. Hence, we will be able to have an insight on the work that we will perform on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext, SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Twitter dataset data collection, from cluster to dataframe\n",
    "\n",
    "In this section, we will make some operation with the help of Spark, to access, filter and export the useful tweets from the cluster to our computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few words about what we noticed for our dataset \n",
    "\n",
    "First, the twitter dataset starts from year 2012.\n",
    "In the date section, the hour has been scaled, so that the tweet time is always relative to GMT+00. This will be of use when we will relate tweet dates and times with the Wikipedia dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Filtering the useful tweets\n",
    "\n",
    "We start by declaring the Spark Context in order to make the link with the cluster. With Spark installed locally, we are able to query the cluster directly in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile(\"hdfs:///datasets/tweets-leon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of our filter is that we want to work with data that is already highly focused on our subject : terrorist  attacks. For the Milestone 2, we implemented a filter that considered different languages. Following the feedback from the TAs, we decided to stick with only English as the language of the tweets and the keywords, to go back to a **more simple, but more precise filter**. When a tweet is passed through the filter, we will compute the tweet score depending on its content and, if the score is high enough, select the tweet to be part of our dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We define below a few helper functions that will be used for our inition filter :** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is the heart of the filter. Five lists are detailed, representing words of different importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words_to_match():\n",
    "    \n",
    "\n",
    "    language = 'en'\n",
    "    \n",
    "    t1 = ['terror attack', 'terrorist attack','suicide bombing','mass shooting']\n",
    "\n",
    "\n",
    "\n",
    "    t2 = ['suicide bomber','car bombing','drone bombing','mass execution','improvised explosive device','truck bomb','grenade attack','train bombing']\n",
    "\n",
    "\n",
    "    t3 = [' ied', 'hijacking','genocide','bomb attack','vehicule attack','assasination','terrorism','weapon','knife','assault rifle','dead','deaths','died','injured','kill','plant','drive-by shooting','hostage','execution']\n",
    "\n",
    "\n",
    "    hashtag = ['#prayfor','#terrorism','#terrorists','#terrorattack']\n",
    "\n",
    "    malus_list = ['years ago','year ago', 'months ago','month ago','anniversary']\n",
    "    \n",
    "    l = [t1,t2,t3,hashtag,malus_list]\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function computes the importance of a tweet by assigning specific weights to every tweet. The assignment is done by iterating on all interesting words, looking whether they occur in the tweet content. According to the word's affiliation to one of the lists, different weight are incremented. If the total weight of the tweet reaches the threshold value (here 1.0), the filter returns True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_interesting(content,l):\n",
    "    \n",
    "    content = content.lower()\n",
    "    \n",
    "    lang = content[:2]\n",
    "    \n",
    "    \n",
    "    weight=0.0\n",
    "    \n",
    "    \n",
    "    \n",
    "    for w in l[0]:\n",
    "        if w in content:\n",
    "            weight+=1.0\n",
    "\n",
    "    for w in l[1]:\n",
    "        if w in content:\n",
    "            weight+=0.9\n",
    "\n",
    "    for w in l[2]:\n",
    "        if w in content:\n",
    "            weight+=0.1\n",
    "             \n",
    "    for w in l[3]:\n",
    "        if w in content:\n",
    "            weight+=0.7\n",
    "            \n",
    "            \n",
    "    for w in l[3]:\n",
    "        if w in content:\n",
    "            weight-=0.5\n",
    "    \n",
    "    return (weight >= 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the variable `bds` to be the three filtering dictionnaries. It will serve as an input of our filtering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bds = words_to_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we actually call spark by filtering the data in the cluster with our filter, to then take a subset of defined size. We proceed to write it to a text file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terrorism = text_file.filter(lambda t: is_interesting(t,bds)).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_t = open('tweets_terror3.txt','w')\n",
    "for item in terrorism:\n",
    "    file_t.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fr\\t345963978092072960\\tSat Jun 15 18:00:14 +0000 2013\\tKazdaliMaaradj\\tPakistan: un double-attentat à la bombe à Quetta (sud-ouest) fait au moins 23 morts (nouveau bilan des autorités locales)',\n",
       " 'en\\t345964011382259712\\tSat Jun 15 18:00:22 +0000 2013\\tSumairaALi4\\t#BLA needs to be targetted in INDIA and UK. ISI should get in motion as were in 80s #JudicialTerrorism',\n",
       " 'en\\t345964045007978497\\tSat Jun 15 18:00:30 +0000 2013\\tMonotheist_\\tUnrest in Baluchistan. BLA terrorism there. Baluch demand justice. Foreign and local intelligence are involved. No one dares to anyone',\n",
       " 'es\\t345964057632837632\\tSat Jun 15 18:00:33 +0000 2013\\texodo3013\\t@akatsuky1000 quien ayudo a librar al pueblo de Libia del terrorista #1 en el mundo Omar K  que masacraba a su pueblo con aviones de guerra',\n",
       " 'es\\t345964070274482176\\tSat Jun 15 18:00:36 +0000 2013\\tCesar_Soto_16\\tCon Los Terroristas - Alianza Metal 1°H: http://t.co/SDT9qzSVHz vía @YouTube']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terrorism[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Handling the filtered tweets\n",
    "\n",
    "#### Some issues we encountered:\n",
    "\n",
    "1)    Tweets can countain retweet so many times the same tweet can appear with a retweet identification: `RT @<username>`\n",
    "    - Resolved by adding Frequency parameter for tweet that has been retweet \n",
    "    - Even tough we separeted the tweet from the retweet some of the tweets appears many time without the Retweet identification. It is still important to distinguish them and not count them many times since we reckon that simply copying a message or retweeting a message has less significance than creating it.\n",
    "    \n",
    "2)    Even if we remove the retweet, some tweets are still the same but have not the same length which can lead to count separetly the same tweet\n",
    "    - Resolved by putting a fixed max length to all tweet\n",
    "    - Or by testing if a string is in another (Complicated solution not adopted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the filtered tweets from the .txt files\n",
    "tweets_raw = pd.read_csv(delimiter=\"\\t\",filepath_or_buffer='tweets_terr.txt', names=[\"lan\",\"id\",\"date\", \"user_name\", \"content\"],encoding='utf-8',quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>user_name</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459658e+17</td>\n",
       "      <td>Sat Jun 15 18:07:17 +0000 2013</td>\n",
       "      <td>SangyeH</td>\n",
       "      <td>RT @AnnieSage: Unbelievable.... @thinkprogress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459658e+17</td>\n",
       "      <td>Sat Jun 15 18:07:27 +0000 2013</td>\n",
       "      <td>SR_Brant</td>\n",
       "      <td>RT @AnnieSage: Unbelievable.... @thinkprogress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459683e+17</td>\n",
       "      <td>Sat Jun 15 18:17:35 +0000 2013</td>\n",
       "      <td>kiraababee</td>\n",
       "      <td>RT @SweaterGawd: I cum faster than the fbi dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459687e+17</td>\n",
       "      <td>Sat Jun 15 18:19:07 +0000 2013</td>\n",
       "      <td>drgauravn85</td>\n",
       "      <td>@asma_rehman02 even your feeder USA is agreed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459700e+17</td>\n",
       "      <td>Sat Jun 15 18:24:06 +0000 2013</td>\n",
       "      <td>WatchTVChannels</td>\n",
       "      <td>Quetta Carnage: 23 killed in terrorist attacks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459731e+17</td>\n",
       "      <td>Sat Jun 15 18:36:29 +0000 2013</td>\n",
       "      <td>geoworld_live</td>\n",
       "      <td>Quetta Carnage: 23 killed in terrorist attacks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459733e+17</td>\n",
       "      <td>Sat Jun 15 18:37:21 +0000 2013</td>\n",
       "      <td>QuddoosMirwani</td>\n",
       "      <td>RT @geonews_english: Quetta Carnage: 23 killed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459734e+17</td>\n",
       "      <td>Sat Jun 15 18:37:44 +0000 2013</td>\n",
       "      <td>faisalzahoor6</td>\n",
       "      <td>Today i  am very sad due to terrorist attack o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459741e+17</td>\n",
       "      <td>Sat Jun 15 18:40:38 +0000 2013</td>\n",
       "      <td>hellosharma</td>\n",
       "      <td>RT @TeaPartyCat: Since Newtown, there have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459744e+17</td>\n",
       "      <td>Sat Jun 15 18:41:28 +0000 2013</td>\n",
       "      <td>Mobisher</td>\n",
       "      <td>RT @cestmoiM: there was a HUGE TERROR ATTACK I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459750e+17</td>\n",
       "      <td>Sat Jun 15 18:44:02 +0000 2013</td>\n",
       "      <td>layladylayy</td>\n",
       "      <td>RT @MetPoIiceUK: 63 Somalis killed in Bradford...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459752e+17</td>\n",
       "      <td>Sat Jun 15 18:44:41 +0000 2013</td>\n",
       "      <td>malikakissxkhan</td>\n",
       "      <td>A few days ago Afghanistan had terror attacks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459755e+17</td>\n",
       "      <td>Sat Jun 15 18:46:02 +0000 2013</td>\n",
       "      <td>stevens1</td>\n",
       "      <td>New poll finds few Massachusetts residents wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459770e+17</td>\n",
       "      <td>Sat Jun 15 18:51:50 +0000 2013</td>\n",
       "      <td>DavidMaly1</td>\n",
       "      <td>RT @TylerBorchers: There have been 14 mass sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>en</td>\n",
       "      <td>3.459790e+17</td>\n",
       "      <td>Sat Jun 15 18:59:54 +0000 2013</td>\n",
       "      <td>cave2u</td>\n",
       "      <td>Slave: \\nSuicide bombers how are you fighting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193742e+17</td>\n",
       "      <td>Wed Apr 03 09:01:56 +0000 2013</td>\n",
       "      <td>7our</td>\n",
       "      <td>Unconfirmed. Aaron Yoon, third possible Canadi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193752e+17</td>\n",
       "      <td>Wed Apr 03 09:06:03 +0000 2013</td>\n",
       "      <td>RT3Algeria</td>\n",
       "      <td>RT @7our: \"School yearbook photos reveal young...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193767e+17</td>\n",
       "      <td>Wed Apr 03 09:11:42 +0000 2013</td>\n",
       "      <td>OmarShabbi</td>\n",
       "      <td>School yearbook photos reveal young faces of C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193795e+17</td>\n",
       "      <td>Wed Apr 03 09:22:52 +0000 2013</td>\n",
       "      <td>frozenliberty</td>\n",
       "      <td>Every mass shooting over last 20 years has one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193810e+17</td>\n",
       "      <td>Wed Apr 03 09:29:01 +0000 2013</td>\n",
       "      <td>DeafRanger</td>\n",
       "      <td>RT @gerfingerpoken: @michaeljohns (IBD) Obama ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193828e+17</td>\n",
       "      <td>Wed Apr 03 09:36:10 +0000 2013</td>\n",
       "      <td>JerimiahLandry</td>\n",
       "      <td>North Koreas False-Flag Bio-Terror Attack Plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>en</td>\n",
       "      <td>3.193883e+17</td>\n",
       "      <td>Wed Apr 03 09:58:10 +0000 2013</td>\n",
       "      <td>morning_dance</td>\n",
       "      <td>#clueless Obama Administration Won’t Call Fort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572551e+17</td>\n",
       "      <td>Sat Oct 13 23:02:38 +0000 2012</td>\n",
       "      <td>UKNCOM</td>\n",
       "      <td>17 dead in Pakistan car bombing (CBS News): Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572603e+17</td>\n",
       "      <td>Sat Oct 13 23:23:31 +0000 2012</td>\n",
       "      <td>MrBlog1</td>\n",
       "      <td>@VotingFemale Team Obama Pulled Security Teams...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572614e+17</td>\n",
       "      <td>Sat Oct 13 23:27:58 +0000 2012</td>\n",
       "      <td>baghdadinformer</td>\n",
       "      <td>#Baghdad Suicide bomber kills at least 7 in Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572626e+17</td>\n",
       "      <td>Sat Oct 13 23:32:38 +0000 2012</td>\n",
       "      <td>heffe67</td>\n",
       "      <td>MASS SHOOTINGS? – Secrets of the Fed http://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572631e+17</td>\n",
       "      <td>Sat Oct 13 23:34:27 +0000 2012</td>\n",
       "      <td>cattinks</td>\n",
       "      <td>RT @BOFailed: On day 1 Americans knew #Benghaz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>en</td>\n",
       "      <td>2.572636e+17</td>\n",
       "      <td>Sat Oct 13 23:36:27 +0000 2012</td>\n",
       "      <td>KolHaolam</td>\n",
       "      <td>GAZA: Two terrorists who planned to carry out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>en</td>\n",
       "      <td>2.417135e+17</td>\n",
       "      <td>Sat Sep 01 01:45:52 +0000 2012</td>\n",
       "      <td>aronsonniles</td>\n",
       "      <td>RT @kr3at: FLASHBACK - Top Clinton Official: O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>en</td>\n",
       "      <td>2.417151e+17</td>\n",
       "      <td>Sat Sep 01 01:52:20 +0000 2012</td>\n",
       "      <td>StarkRP</td>\n",
       "      <td>@Morgan_Ember I was dreaming of my terrorist a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548818</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938538e+17</td>\n",
       "      <td>Sun Jan 31 17:50:09 +0000 2016</td>\n",
       "      <td>lwest16</td>\n",
       "      <td>RT @col_nj: Obama to Speak at Baltimore Mosque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548819</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938606e+17</td>\n",
       "      <td>Sun Jan 31 18:17:07 +0000 2016</td>\n",
       "      <td>mgillaspie</td>\n",
       "      <td>RT @juanitamoutlaw: 'Palestinian' Security Off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548820</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938648e+17</td>\n",
       "      <td>Sun Jan 31 18:33:55 +0000 2016</td>\n",
       "      <td>CamBam8</td>\n",
       "      <td>RT @BringTheFlag: Obama to Speak at Baltimore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548821</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938660e+17</td>\n",
       "      <td>Sun Jan 31 18:38:31 +0000 2016</td>\n",
       "      <td>LottRan</td>\n",
       "      <td>RT @joelpollak: Obama to Speak at Baltimore Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548822</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938678e+17</td>\n",
       "      <td>Sun Jan 31 18:45:44 +0000 2016</td>\n",
       "      <td>AgSilverSurfer</td>\n",
       "      <td>'Palestinian' Security Officer Wounds 3 Jewish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548823</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938707e+17</td>\n",
       "      <td>Sun Jan 31 18:57:14 +0000 2016</td>\n",
       "      <td>Unity_Love_Hope</td>\n",
       "      <td>RT @jchaltiwanger: And suicide bombing in Dama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548824</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938723e+17</td>\n",
       "      <td>Sun Jan 31 19:03:41 +0000 2016</td>\n",
       "      <td>PMoallemian</td>\n",
       "      <td>Iran condemns terror attacks near holy shrine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548825</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938731e+17</td>\n",
       "      <td>Sun Jan 31 19:06:54 +0000 2016</td>\n",
       "      <td>bubby_gee</td>\n",
       "      <td>RT @KenRoth: ISIS car bomb kills Shia civilian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548826</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938746e+17</td>\n",
       "      <td>Sun Jan 31 19:12:53 +0000 2016</td>\n",
       "      <td>pattriotpat</td>\n",
       "      <td>‘Palestinian’ Security Officer Wounds 3 Jewish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548827</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938848e+17</td>\n",
       "      <td>Sun Jan 31 19:53:14 +0000 2016</td>\n",
       "      <td>mohdabbas110</td>\n",
       "      <td>RT @HadiQazwini: We live in an era where innoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548828</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938860e+17</td>\n",
       "      <td>Sun Jan 31 19:57:58 +0000 2016</td>\n",
       "      <td>stick375</td>\n",
       "      <td>RT @WalshFreedom: Obama to speak at Baltimore ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548829</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938861e+17</td>\n",
       "      <td>Sun Jan 31 19:58:29 +0000 2016</td>\n",
       "      <td>mikeneffff</td>\n",
       "      <td>Suicide Bombings Kill at Least 45 Near Damascu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548830</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938862e+17</td>\n",
       "      <td>Sun Jan 31 19:58:47 +0000 2016</td>\n",
       "      <td>I_am_Freezboi</td>\n",
       "      <td>No one is talking about the over 100 people th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548831</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938865e+17</td>\n",
       "      <td>Sun Jan 31 20:00:17 +0000 2016</td>\n",
       "      <td>CaptainFeminist</td>\n",
       "      <td>RT @musicaIhoe: obama didn't ask for more gun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548832</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938870e+17</td>\n",
       "      <td>Sun Jan 31 20:02:03 +0000 2016</td>\n",
       "      <td>UKforMe</td>\n",
       "      <td>https://t.co/PHsU4UYNIH ISIS killers threaten ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548833</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938933e+17</td>\n",
       "      <td>Sun Jan 31 20:27:13 +0000 2016</td>\n",
       "      <td>Gjoene</td>\n",
       "      <td>RT @LinaArabii: Your average alJazeera journo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548834</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938938e+17</td>\n",
       "      <td>Sun Jan 31 20:29:08 +0000 2016</td>\n",
       "      <td>LakeShow_209</td>\n",
       "      <td>RT @theGOAPT: @byjoelanderson let me get this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548835</th>\n",
       "      <td>en</td>\n",
       "      <td>6.938976e+17</td>\n",
       "      <td>Sun Jan 31 20:44:05 +0000 2016</td>\n",
       "      <td>Shantal_xx</td>\n",
       "      <td>RT @lNVENTlONS: Bulletproof blankets designed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548836</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939025e+17</td>\n",
       "      <td>Sun Jan 31 21:03:47 +0000 2016</td>\n",
       "      <td>TechNewsTrend</td>\n",
       "      <td>Mass shootings may have a contagious effect, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548837</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939061e+17</td>\n",
       "      <td>Sun Jan 31 21:17:55 +0000 2016</td>\n",
       "      <td>SCMI85</td>\n",
       "      <td>RT @CUFI: Join us in praying for the IDF soldi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548838</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939094e+17</td>\n",
       "      <td>Sun Jan 31 21:31:01 +0000 2016</td>\n",
       "      <td>OemorOniluap</td>\n",
       "      <td>RT @nytimes: A double suicide bombing kills at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548839</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939140e+17</td>\n",
       "      <td>Sun Jan 31 21:49:23 +0000 2016</td>\n",
       "      <td>MyInfo70343371</td>\n",
       "      <td>RT @GrrrGraphics: Another cartoon spot on! Oba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548840</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939146e+17</td>\n",
       "      <td>Sun Jan 31 21:51:54 +0000 2016</td>\n",
       "      <td>HarryPotterHoe</td>\n",
       "      <td>RT @Incendiotp: @Incendiotp this edit was made...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548841</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939186e+17</td>\n",
       "      <td>Sun Jan 31 22:07:38 +0000 2016</td>\n",
       "      <td>Sylvaners</td>\n",
       "      <td>At Least 45 Killed In Triple Bombing Near Dama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548842</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939255e+17</td>\n",
       "      <td>Sun Jan 31 22:35:13 +0000 2016</td>\n",
       "      <td>GL650_LynneG</td>\n",
       "      <td>RT @Telegraph: A propaganda newspaper from Isi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548843</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939309e+17</td>\n",
       "      <td>Sun Jan 31 22:56:44 +0000 2016</td>\n",
       "      <td>freewimin</td>\n",
       "      <td>RT @CharlesMBlow: If you are aghast at terror ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548844</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939311e+17</td>\n",
       "      <td>Sun Jan 31 22:57:13 +0000 2016</td>\n",
       "      <td>orion99da</td>\n",
       "      <td>RT @weknowwhatsbest: Pres Obama will not comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548845</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939345e+17</td>\n",
       "      <td>Sun Jan 31 23:10:41 +0000 2016</td>\n",
       "      <td>ghostofhypotia</td>\n",
       "      <td>RT @CharlesMBlow: If you are aghast at terror ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548846</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939404e+17</td>\n",
       "      <td>Sun Jan 31 23:34:22 +0000 2016</td>\n",
       "      <td>Fhilosofile</td>\n",
       "      <td>Where is the West's compassion &amp;amp; condemnat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548847</th>\n",
       "      <td>en</td>\n",
       "      <td>6.939445e+17</td>\n",
       "      <td>Sun Jan 31 23:50:26 +0000 2016</td>\n",
       "      <td>MakebaUhuru</td>\n",
       "      <td>RT @NaelSanaullah: Thank God it was a biker ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548848 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lan            id                            date        user_name  \\\n",
       "0       en  3.459658e+17  Sat Jun 15 18:07:17 +0000 2013          SangyeH   \n",
       "1       en  3.459658e+17  Sat Jun 15 18:07:27 +0000 2013         SR_Brant   \n",
       "2       en  3.459683e+17  Sat Jun 15 18:17:35 +0000 2013       kiraababee   \n",
       "3       en  3.459687e+17  Sat Jun 15 18:19:07 +0000 2013      drgauravn85   \n",
       "4       en  3.459700e+17  Sat Jun 15 18:24:06 +0000 2013  WatchTVChannels   \n",
       "5       en  3.459731e+17  Sat Jun 15 18:36:29 +0000 2013    geoworld_live   \n",
       "6       en  3.459733e+17  Sat Jun 15 18:37:21 +0000 2013   QuddoosMirwani   \n",
       "7       en  3.459734e+17  Sat Jun 15 18:37:44 +0000 2013    faisalzahoor6   \n",
       "8       en  3.459741e+17  Sat Jun 15 18:40:38 +0000 2013      hellosharma   \n",
       "9       en  3.459744e+17  Sat Jun 15 18:41:28 +0000 2013         Mobisher   \n",
       "10      en  3.459750e+17  Sat Jun 15 18:44:02 +0000 2013      layladylayy   \n",
       "11      en  3.459752e+17  Sat Jun 15 18:44:41 +0000 2013  malikakissxkhan   \n",
       "12      en  3.459755e+17  Sat Jun 15 18:46:02 +0000 2013         stevens1   \n",
       "13      en  3.459770e+17  Sat Jun 15 18:51:50 +0000 2013       DavidMaly1   \n",
       "14      en  3.459790e+17  Sat Jun 15 18:59:54 +0000 2013           cave2u   \n",
       "15      en  3.193742e+17  Wed Apr 03 09:01:56 +0000 2013             7our   \n",
       "16      en  3.193752e+17  Wed Apr 03 09:06:03 +0000 2013       RT3Algeria   \n",
       "17      en  3.193767e+17  Wed Apr 03 09:11:42 +0000 2013       OmarShabbi   \n",
       "18      en  3.193795e+17  Wed Apr 03 09:22:52 +0000 2013    frozenliberty   \n",
       "19      en  3.193810e+17  Wed Apr 03 09:29:01 +0000 2013       DeafRanger   \n",
       "20      en  3.193828e+17  Wed Apr 03 09:36:10 +0000 2013   JerimiahLandry   \n",
       "21      en  3.193883e+17  Wed Apr 03 09:58:10 +0000 2013    morning_dance   \n",
       "22      en  2.572551e+17  Sat Oct 13 23:02:38 +0000 2012           UKNCOM   \n",
       "23      en  2.572603e+17  Sat Oct 13 23:23:31 +0000 2012          MrBlog1   \n",
       "24      en  2.572614e+17  Sat Oct 13 23:27:58 +0000 2012  baghdadinformer   \n",
       "25      en  2.572626e+17  Sat Oct 13 23:32:38 +0000 2012          heffe67   \n",
       "26      en  2.572631e+17  Sat Oct 13 23:34:27 +0000 2012         cattinks   \n",
       "27      en  2.572636e+17  Sat Oct 13 23:36:27 +0000 2012        KolHaolam   \n",
       "28      en  2.417135e+17  Sat Sep 01 01:45:52 +0000 2012     aronsonniles   \n",
       "29      en  2.417151e+17  Sat Sep 01 01:52:20 +0000 2012          StarkRP   \n",
       "...     ..           ...                             ...              ...   \n",
       "548818  en  6.938538e+17  Sun Jan 31 17:50:09 +0000 2016          lwest16   \n",
       "548819  en  6.938606e+17  Sun Jan 31 18:17:07 +0000 2016       mgillaspie   \n",
       "548820  en  6.938648e+17  Sun Jan 31 18:33:55 +0000 2016          CamBam8   \n",
       "548821  en  6.938660e+17  Sun Jan 31 18:38:31 +0000 2016          LottRan   \n",
       "548822  en  6.938678e+17  Sun Jan 31 18:45:44 +0000 2016   AgSilverSurfer   \n",
       "548823  en  6.938707e+17  Sun Jan 31 18:57:14 +0000 2016  Unity_Love_Hope   \n",
       "548824  en  6.938723e+17  Sun Jan 31 19:03:41 +0000 2016      PMoallemian   \n",
       "548825  en  6.938731e+17  Sun Jan 31 19:06:54 +0000 2016        bubby_gee   \n",
       "548826  en  6.938746e+17  Sun Jan 31 19:12:53 +0000 2016      pattriotpat   \n",
       "548827  en  6.938848e+17  Sun Jan 31 19:53:14 +0000 2016     mohdabbas110   \n",
       "548828  en  6.938860e+17  Sun Jan 31 19:57:58 +0000 2016         stick375   \n",
       "548829  en  6.938861e+17  Sun Jan 31 19:58:29 +0000 2016       mikeneffff   \n",
       "548830  en  6.938862e+17  Sun Jan 31 19:58:47 +0000 2016    I_am_Freezboi   \n",
       "548831  en  6.938865e+17  Sun Jan 31 20:00:17 +0000 2016  CaptainFeminist   \n",
       "548832  en  6.938870e+17  Sun Jan 31 20:02:03 +0000 2016          UKforMe   \n",
       "548833  en  6.938933e+17  Sun Jan 31 20:27:13 +0000 2016           Gjoene   \n",
       "548834  en  6.938938e+17  Sun Jan 31 20:29:08 +0000 2016     LakeShow_209   \n",
       "548835  en  6.938976e+17  Sun Jan 31 20:44:05 +0000 2016       Shantal_xx   \n",
       "548836  en  6.939025e+17  Sun Jan 31 21:03:47 +0000 2016    TechNewsTrend   \n",
       "548837  en  6.939061e+17  Sun Jan 31 21:17:55 +0000 2016           SCMI85   \n",
       "548838  en  6.939094e+17  Sun Jan 31 21:31:01 +0000 2016     OemorOniluap   \n",
       "548839  en  6.939140e+17  Sun Jan 31 21:49:23 +0000 2016   MyInfo70343371   \n",
       "548840  en  6.939146e+17  Sun Jan 31 21:51:54 +0000 2016   HarryPotterHoe   \n",
       "548841  en  6.939186e+17  Sun Jan 31 22:07:38 +0000 2016        Sylvaners   \n",
       "548842  en  6.939255e+17  Sun Jan 31 22:35:13 +0000 2016     GL650_LynneG   \n",
       "548843  en  6.939309e+17  Sun Jan 31 22:56:44 +0000 2016        freewimin   \n",
       "548844  en  6.939311e+17  Sun Jan 31 22:57:13 +0000 2016        orion99da   \n",
       "548845  en  6.939345e+17  Sun Jan 31 23:10:41 +0000 2016   ghostofhypotia   \n",
       "548846  en  6.939404e+17  Sun Jan 31 23:34:22 +0000 2016      Fhilosofile   \n",
       "548847  en  6.939445e+17  Sun Jan 31 23:50:26 +0000 2016      MakebaUhuru   \n",
       "\n",
       "                                                  content  \n",
       "0       RT @AnnieSage: Unbelievable.... @thinkprogress...  \n",
       "1       RT @AnnieSage: Unbelievable.... @thinkprogress...  \n",
       "2       RT @SweaterGawd: I cum faster than the fbi dur...  \n",
       "3       @asma_rehman02 even your feeder USA is agreed ...  \n",
       "4       Quetta Carnage: 23 killed in terrorist attacks...  \n",
       "5       Quetta Carnage: 23 killed in terrorist attacks...  \n",
       "6       RT @geonews_english: Quetta Carnage: 23 killed...  \n",
       "7       Today i  am very sad due to terrorist attack o...  \n",
       "8       RT @TeaPartyCat: Since Newtown, there have bee...  \n",
       "9       RT @cestmoiM: there was a HUGE TERROR ATTACK I...  \n",
       "10      RT @MetPoIiceUK: 63 Somalis killed in Bradford...  \n",
       "11      A few days ago Afghanistan had terror attacks ...  \n",
       "12      New poll finds few Massachusetts residents wor...  \n",
       "13      RT @TylerBorchers: There have been 14 mass sho...  \n",
       "14      Slave: \\nSuicide bombers how are you fighting ...  \n",
       "15      Unconfirmed. Aaron Yoon, third possible Canadi...  \n",
       "16      RT @7our: \"School yearbook photos reveal young...  \n",
       "17      School yearbook photos reveal young faces of C...  \n",
       "18      Every mass shooting over last 20 years has one...  \n",
       "19      RT @gerfingerpoken: @michaeljohns (IBD) Obama ...  \n",
       "20      North Koreas False-Flag Bio-Terror Attack Plan...  \n",
       "21      #clueless Obama Administration Won’t Call Fort...  \n",
       "22      17 dead in Pakistan car bombing (CBS News): Sh...  \n",
       "23      @VotingFemale Team Obama Pulled Security Teams...  \n",
       "24      #Baghdad Suicide bomber kills at least 7 in Ba...  \n",
       "25      MASS SHOOTINGS? – Secrets of the Fed http://t....  \n",
       "26      RT @BOFailed: On day 1 Americans knew #Benghaz...  \n",
       "27      GAZA: Two terrorists who planned to carry out ...  \n",
       "28      RT @kr3at: FLASHBACK - Top Clinton Official: O...  \n",
       "29      @Morgan_Ember I was dreaming of my terrorist a...  \n",
       "...                                                   ...  \n",
       "548818  RT @col_nj: Obama to Speak at Baltimore Mosque...  \n",
       "548819  RT @juanitamoutlaw: 'Palestinian' Security Off...  \n",
       "548820  RT @BringTheFlag: Obama to Speak at Baltimore ...  \n",
       "548821  RT @joelpollak: Obama to Speak at Baltimore Mo...  \n",
       "548822  'Palestinian' Security Officer Wounds 3 Jewish...  \n",
       "548823  RT @jchaltiwanger: And suicide bombing in Dama...  \n",
       "548824  Iran condemns terror attacks near holy shrine ...  \n",
       "548825  RT @KenRoth: ISIS car bomb kills Shia civilian...  \n",
       "548826  ‘Palestinian’ Security Officer Wounds 3 Jewish...  \n",
       "548827  RT @HadiQazwini: We live in an era where innoc...  \n",
       "548828  RT @WalshFreedom: Obama to speak at Baltimore ...  \n",
       "548829  Suicide Bombings Kill at Least 45 Near Damascu...  \n",
       "548830  No one is talking about the over 100 people th...  \n",
       "548831  RT @musicaIhoe: obama didn't ask for more gun ...  \n",
       "548832  https://t.co/PHsU4UYNIH ISIS killers threaten ...  \n",
       "548833  RT @LinaArabii: Your average alJazeera journo ...  \n",
       "548834  RT @theGOAPT: @byjoelanderson let me get this ...  \n",
       "548835  RT @lNVENTlONS: Bulletproof blankets designed ...  \n",
       "548836  Mass shootings may have a contagious effect, a...  \n",
       "548837  RT @CUFI: Join us in praying for the IDF soldi...  \n",
       "548838  RT @nytimes: A double suicide bombing kills at...  \n",
       "548839  RT @GrrrGraphics: Another cartoon spot on! Oba...  \n",
       "548840  RT @Incendiotp: @Incendiotp this edit was made...  \n",
       "548841  At Least 45 Killed In Triple Bombing Near Dama...  \n",
       "548842  RT @Telegraph: A propaganda newspaper from Isi...  \n",
       "548843  RT @CharlesMBlow: If you are aghast at terror ...  \n",
       "548844  RT @weknowwhatsbest: Pres Obama will not comme...  \n",
       "548845  RT @CharlesMBlow: If you are aghast at terror ...  \n",
       "548846  Where is the West's compassion &amp; condemnat...  \n",
       "548847  RT @NaelSanaullah: Thank God it was a biker ga...  \n",
       "\n",
       "[548848 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, the id and user name of the tweet is useless, we keep therefore only the language, the date and the content of the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_raw = tweets_raw.drop(axis= 1, labels=  [\"id\", \"user_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date countained in the tweets has been translated into `GMT` 0. So we do not have to worry about translating the date and can directly standarize with the dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parser must be a string or character stream, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-81667de5262f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We parse the date to have a uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66645)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-81667de5262f>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(d)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We parse the date to have a uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtweets_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m                                                       second=0, microsecond=0)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipped_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_timelex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Splits the timestr into tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;31m# keep up with the last token skipped so we can recombine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ada/lib/python3.5/site-packages/dateutil/parser.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, instream)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'read'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             raise TypeError('Parser must be a string or character stream, not '\n\u001b[0;32m---> 61\u001b[0;31m                             '{itype}'.format(itype=instream.__class__.__name__))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parser must be a string or character stream, not float"
     ]
    }
   ],
   "source": [
    "#We parse the date to have a uniform \n",
    "tweets_raw[\"date\"] = tweets_raw[\"date\"].apply(lambda d: parse(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = tweets_raw.copy()\n",
    "tweets[\"retweet\"] =  tweets[\"content\"].map(lambda s : s[0:4] == \"RT @\") #Is it a retweet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to normalize our tweet to handle 1) and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Maximum length that we allowed to have in oder to not have different tweet\n",
    "\n",
    "MAX_LEN = 140 - 15 - 10  # Limit of a tweet minus the maximum user name \n",
    "                         # and other charachter added when a retweet is created\n",
    "\n",
    "\n",
    "def remove_retweet_and_cut(t):\n",
    "    \"\"\"\n",
    "    Function that remove the RT @ in front of a tweet if it has been detected as a retweet, \n",
    "    And cut the tweet according to the MAX_LEN parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    if(t[\"retweet\"]):\n",
    "        return ' '.join(t[\"content\"].split()[2:])[0:MAX_LEN]\n",
    "    else :\n",
    "        return t[\"content\"][0:MAX_LEN]\n",
    "    \n",
    "\n",
    "    \n",
    "#Apply the function we just created    \n",
    "tweets[\"content\"] =  tweets.apply(remove_retweet_and_cut, axis = 1)\n",
    "\n",
    "\n",
    "#------------------------- Handling the frequency of a tweet ---------------------\n",
    "\n",
    "\n",
    "# We create a dict to map the content and the frequency that a tweet with the same content occur.\n",
    "freq_dict = dict(tweets.groupby(\"content\")[\"lan\"].count())\n",
    "\n",
    "\n",
    "tweets = tweets.drop_duplicates(subset=\"content\")\n",
    "\n",
    "\n",
    "tweets[\"frequency\"] = tweets[\"content\"].map(lambda c : freq_dict[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We end up with a nice dataframe of the filtered tweets with the frequency of each tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>retweet</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-08-02 12:00:53+00:00</td>\n",
       "      <td>Zayn is NOT a terrorist.\\nZayn donated for cha...</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-07-16 04:00:12+00:00</td>\n",
       "      <td>The whites agree to stop blaming all Arab's fo...</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-06-15 18:01:53+00:00</td>\n",
       "      <td>Black Crime =Gang Violence. \\nArab Crime = Ter...</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>fr</td>\n",
       "      <td>2013-07-08 10:40:40+00:00</td>\n",
       "      <td>RTsi arabe a la piscine :\\n-Jvais faire la bom...</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>es</td>\n",
       "      <td>2012-10-06 14:00:21+00:00</td>\n",
       "      <td>Cuba demanda justicia en el Día de las Víctima...</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lan                      date  \\\n",
       "2153  en 2013-08-02 12:00:53+00:00   \n",
       "769   en 2013-07-16 04:00:12+00:00   \n",
       "8     en 2013-06-15 18:01:53+00:00   \n",
       "3596  fr 2013-07-08 10:40:40+00:00   \n",
       "3257  es 2012-10-06 14:00:21+00:00   \n",
       "\n",
       "                                                content  retweet  frequency  \n",
       "2153  Zayn is NOT a terrorist.\\nZayn donated for cha...     True         37  \n",
       "769   The whites agree to stop blaming all Arab's fo...     True         25  \n",
       "8     Black Crime =Gang Violence. \\nArab Crime = Ter...     True         19  \n",
       "3596  RTsi arabe a la piscine :\\n-Jvais faire la bom...     True         16  \n",
       "3257  Cuba demanda justicia en el Día de las Víctima...    False         15  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.sort_values(by=\"frequency\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lan</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>retweet</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fr</td>\n",
       "      <td>2013-06-15 18:00:14+00:00</td>\n",
       "      <td>Pakistan: un double-attentat à la bombe à Quet...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-08-02 12:29:20+00:00</td>\n",
       "      <td>@RuckaRuckaAli I love reading how these holy #...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>es</td>\n",
       "      <td>2013-08-02 12:29:21+00:00</td>\n",
       "      <td>#UnDíaComoHoy pero de 1980: en la estación fer...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-08-02 12:29:24+00:00</td>\n",
       "      <td>@Harry_Styles I love you. Please follow me my ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>en</td>\n",
       "      <td>2013-08-02 12:29:27+00:00</td>\n",
       "      <td>@NancyAtwal: You call him a terrorist I call h...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lan                      date  \\\n",
       "0     fr 2013-06-15 18:00:14+00:00   \n",
       "2609  en 2013-08-02 12:29:20+00:00   \n",
       "2610  es 2013-08-02 12:29:21+00:00   \n",
       "2612  en 2013-08-02 12:29:24+00:00   \n",
       "2614  en 2013-08-02 12:29:27+00:00   \n",
       "\n",
       "                                                content  retweet  frequency  \n",
       "0     Pakistan: un double-attentat à la bombe à Quet...    False          1  \n",
       "2609  @RuckaRuckaAli I love reading how these holy #...    False          1  \n",
       "2610  #UnDíaComoHoy pero de 1980: en la estación fer...    False          1  \n",
       "2612  @Harry_Styles I love you. Please follow me my ...    False          1  \n",
       "2614  @NancyAtwal: You call him a terrorist I call h...    False          1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here are the single tweets\n",
    "tweets.sort_values(by=\"frequency\", ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see below that the ratio of retweet is consequent. \n",
    "Indeed, roughly 1/3 of our filtered tweets have been retweeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3538555318500457"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"retweet\"].sum()/len(tweets.retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grp_tweet = tweets.groupby(\"lan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lan\n",
       "en    2388\n",
       "es     688\n",
       "fr      96\n",
       "it      79\n",
       "nl      30\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_tweet[\"content\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that, not surprisingly, we have more english tweets than the other languages. Indeed english is the most common widespread language and spanish the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we scrape data from Wikipedia. We want to access the tables that register the terror attacks that happened at some point in the past. There are some Wikipedia articles (such as https://en.wikipedia.org/wiki/List_of_terrorist_incidents_in_January-June_2011) that do exactly that. The data is presented as tables, and all the articles that we need present data in this form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simple map of month name to its number\n",
    "month_to_int = {\n",
    "    'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June': 6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "\n",
    "# Reversed map\n",
    "int_to_month = {i: m for m, i in month_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The wikipedia URL that every article has in common\n",
    "base_url = 'https://en.wikipedia.org/wiki/List_of_terrorist_incidents_in_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show all the articles that we are going to use to find the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['January-June_2011',\n",
       " 'July-December_2011',\n",
       " 'January-June_2012',\n",
       " 'July-December_2012',\n",
       " 'January-June_2013',\n",
       " 'July-December_2013',\n",
       " 'January-June_2014',\n",
       " 'July-December_2014',\n",
       " 'January_2015',\n",
       " 'February_2015',\n",
       " 'March_2015',\n",
       " 'April_2015',\n",
       " 'May_2015',\n",
       " 'June_2015',\n",
       " 'July_2015',\n",
       " 'August_2015',\n",
       " 'September_2015',\n",
       " 'October_2015',\n",
       " 'November_2015',\n",
       " 'December_2015',\n",
       " 'January_2016',\n",
       " 'February_2016',\n",
       " 'March_2016',\n",
       " 'April_2016',\n",
       " 'May_2016',\n",
       " 'June_2016',\n",
       " 'July_2016',\n",
       " 'August_2016',\n",
       " 'September_2016',\n",
       " 'October_2016',\n",
       " 'November_2016',\n",
       " 'December_2016',\n",
       " 'January_2017',\n",
       " 'February_2017',\n",
       " 'March_2017',\n",
       " 'April_2017',\n",
       " 'May_2017',\n",
       " 'June_2017',\n",
       " 'July_2017',\n",
       " 'August_2017',\n",
       " 'September_2017',\n",
       " 'October_2017',\n",
       " 'November_2017',\n",
       " 'December_2017']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All specific end of the wikipedia URL, along with the corresponding month numbers of the article\n",
    "times = {}\n",
    "\n",
    "for year in range(2011, 2015):\n",
    "    # For years 2011 to 2014, the articles appear biyearly\n",
    "    times.update({'January-June_' + str(year): list(range(1, 7))})\n",
    "    times.update({'July-December_' + str(year): list(range(7, 13))})\n",
    "    \n",
    "for year in range(2015, 2018):\n",
    "    # For years 2015 to 2017, the articles appear monthly\n",
    "    for month, int_ in month_to_int.items():\n",
    "        times.update({month + '_' + str(year): [int_]})\n",
    "        \n",
    "list(times.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_int(s):\n",
    "    '''Returns the first integer found in s'''\n",
    "    i = re.findall('\\d+', s)\n",
    "    return int(i[0]) if len(i) > 0 else float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_date(s, year):\n",
    "    '''Returns a date from the datetime library from a string like \\'January 1\\''''\n",
    "    l = s.split(' ')\n",
    "    return date(to_int(year), month_to_int[l[0]], to_int(l[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wiki_table_to_df(end_url, month_range, base_url=base_url):\n",
    "    '''Creates a dataframe from the tables available in the wikipedia page'''\n",
    "    print('Scraping for', end_url)\n",
    "    r = requests.get(base_url + end_url) # Get request\n",
    "    soup = BeautifulSoup(r.text, 'lxml') # Parse HTML\n",
    "    wiki_tables = soup.findAll('table', {'class': 'wikitable sortable'}) # Get tables from the wikipedia page\n",
    "\n",
    "    table = []\n",
    "\n",
    "    for month_int, wiki_table in zip(month_range, wiki_tables):\n",
    "        for row in wiki_table.findAll('tr'):\n",
    "            elems = row.findAll('td') \n",
    "            if len(elems) != 0:\n",
    "                interesting = [elem.text for elem in elems[:5]]\n",
    "                 # First element is the day of the month, but we add the name of the month as well in front of it\n",
    "                interesting[0] = int_to_month[month_int] + ' ' + interesting[0]\n",
    "                table.append(interesting)\n",
    "                \n",
    "    df = pd.DataFrame(table, columns=['date', 'type', 'deaths', 'injuries', 'location'])\n",
    "    df.date = df.date.apply(lambda s: to_date(s, end_url[-4:])) # Translate the date with the year defined by the end_url arg\n",
    "    df.deaths = df.deaths.apply(to_int) # Map death number to int\n",
    "    df.injuries = df.injuries.apply(to_int) # Map injuries number to int\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping for January-June_2011\n",
      "Scraping for July-December_2011\n",
      "Scraping for January-June_2012\n",
      "Scraping for July-December_2012\n",
      "Scraping for January-June_2013\n",
      "Scraping for July-December_2013\n",
      "Scraping for January-June_2014\n",
      "Scraping for July-December_2014\n",
      "Scraping for January_2015\n",
      "Scraping for February_2015\n",
      "Scraping for March_2015\n",
      "Scraping for April_2015\n",
      "Scraping for May_2015\n",
      "Scraping for June_2015\n",
      "Scraping for July_2015\n",
      "Scraping for August_2015\n",
      "Scraping for September_2015\n",
      "Scraping for October_2015\n",
      "Scraping for November_2015\n",
      "Scraping for December_2015\n",
      "Scraping for January_2016\n",
      "Scraping for February_2016\n",
      "Scraping for March_2016\n",
      "Scraping for April_2016\n",
      "Scraping for May_2016\n",
      "Scraping for June_2016\n",
      "Scraping for July_2016\n",
      "Scraping for August_2016\n",
      "Scraping for September_2016\n",
      "Scraping for October_2016\n",
      "Scraping for November_2016\n",
      "Scraping for December_2016\n",
      "Scraping for January_2017\n",
      "Scraping for February_2017\n",
      "Scraping for March_2017\n",
      "Scraping for April_2017\n",
      "Scraping for May_2017\n",
      "Scraping for June_2017\n",
      "Scraping for July_2017\n",
      "Scraping for August_2017\n",
      "Scraping for September_2017\n",
      "Scraping for October_2017\n",
      "Scraping for November_2017\n",
      "Scraping for December_2017\n",
      "We have 4664 registered attacks from January 1st, 2011 up to today (November 28th, 2017)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "# Get a DataFrame for every article from 2011 to 2017\n",
    "for time, month_range in times.items():\n",
    "    dfs.append(wiki_table_to_df(time, month_range))\n",
    "    \n",
    "df = pd.concat(dfs)\n",
    "print('We have {} registered attacks from January 1st, 2011 up to today (November 28th, 2017)'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what some of the entries of the final result look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>deaths</th>\n",
       "      <th>injuries</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>Suicide bombing</td>\n",
       "      <td>21.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Alexandria, Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>56</td>\n",
       "      <td>2011-02-13</td>\n",
       "      <td>Raid</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Zamboanga, Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>37</td>\n",
       "      <td>2014-11-18</td>\n",
       "      <td>Shooting, Melee attack</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Jerusalem, Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4663</th>\n",
       "      <td>41</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>Bombing</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kandahar province, Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index        date                    type  deaths  injuries  \\\n",
       "0         0  2011-01-01         Suicide bombing    21.0      97.0   \n",
       "56       56  2011-02-13                    Raid     7.0       5.0   \n",
       "1033     37  2014-11-18  Shooting, Melee attack     5.0       7.0   \n",
       "4663     41  2017-11-28                 Bombing     8.0       NaN   \n",
       "\n",
       "                            location  \n",
       "0                  Alexandria, Egypt  \n",
       "56            Zamboanga, Philippines  \n",
       "1033               Jerusalem, Israel  \n",
       "4663  Kandahar province, Afghanistan  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[[0, 56, 1033, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reindex and save\n",
    "df.to_csv('attacks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making sense of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INFO SUR LA DATA : 548847 Tweets, s'arrete le 31 Jan 2016\n",
    "\n",
    "- reussir a importer dans dataframe\n",
    "- enlever wiki data apres dernier tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Create new DataFrame with Tweets and Wiki data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DF : **date, attack type, city, country, real impact, deads, injured, social impact, number of tweets**\n",
    "\n",
    "- to merge both : match with date of event, and maybe a function that gives a matching score (name of town, country)\n",
    "- take into account the tweets from the date to a certain amount of days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot the attacks in a map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- highlight the real impacts and the social impact\n",
    "- folium ? ideally, map with circles for real impact, and (also circle ?) for social impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Other graphs/info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all the #prayfor : list the different towns\n",
    "- number of attacks/deaths by country (only taken from **Wikipedia dataset**)\n",
    "- ranking of the most liked/ignored attack (just divide social impact by real impact)\n",
    "- same but with country (aggregate social and total impact from before (more relevant than previous point)\n",
    "- maybe see the rise of ISIS ? find by keyword (ISIS) and check with the timeline (graph ISIS claimed vs time, **Wikipedia dataset**)\n",
    "- finally, see the fading of reactions over time \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec la partie 3.2 et 3.3, on devrait avoir assez d'info a leur montrer ! \n",
    "\n",
    "Et si on galère niveau temps, on se replie sur displayer des trucs sur le dataset wikipedia !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
